# 行人重识别ppt稿子


老师同学们大家好，我是左玉晖
今天带来的文章是基于时空图卷积的视频行人重识别
我们先来看一下题目，一部分是视频的行人重识别，一部分是时空图卷积
先来介绍一下行人重识别

行人重识别算是一个很老的问题了
每年都有很多文章是关于他的
行人重识别  
读
那么他能干什么呢

打个比方，在迪士尼一个小孩走丢了，我们肯定是要去监控视频中去找。那么那么大的迪士尼，那么多监控太难找了。那么就需要行人重识别，让计算机去帮着找。
像下面这幅图，输入小女孩图像，在视频序列的所有行人目标里去找。


再来聊一下时空图卷积，时空图卷积是图神经网络的一种，
传统深度学习模型 LSTM 和 CNN 在欧几里得空间数据(语言，图像，视频等)上取得了不错的成绩，但是在对非欧几里得空间数据(eg：社交网络、信息网络等)进行处理上却存在一定的局限性
那么这篇文章显然是属于图像领域的处理的是图像数据，怎么用图卷积呢？
带着这几个问题我们来看这个文章
读

先看文章说说的前人的工作问题
读
这当然也是行人重识别领域普遍存在的问题
其实现在有些办法已经识别精度很高了，行人重识别现在主要是落地问题。

来看一下这些问题。
分辨率低，有遮挡，视角变化，光照变化，视觉模糊。
他和人脸识别不同，人脸识别的图像都是经过摄像头对齐相对高清的图片。
这也是行人重识别的难度所在。


现在已有的处理方法是，
用cnn rnn分别在视频的空间中和时间序列中提取特征。
这样做精度不高，而且非常麻烦。

然后是基于时间序列池化和时空注意力机制的方法，
这些方法没有充分考虑人体各部分在不同帧之间的时间关系，效果有限。

还一个就是AMOC基于光流法的一个运动信息网络，健壮性不强，计算量大也很耗时。

接下来看看作者是怎么解决这些挑战的
读
也就是提出时空图卷积网络来应用到这，多少还是有点堆积网络模型的意思。

读
学习帧间关系

读
基于视频能学到更多的特征

来看他如何构建图结构
一是让不同帧直接相同的部位进行链接
二在同一帧下各个身体部位直接进行链接
这么构图其实是最简陋的一种，之后我来说说我的想法。

作者主要就是提出了这个网络模型结构。
先通过骨干网络 比如resnet提取出feature map特征
一部分切分成patches后放到STGCN中分别按之前说的两种构图方式进行学习
在帧与帧直接建模学习的就是时域GCN
在一帧中进行建模的就是空域GCN
得到两个结果loss后和全局的featuremap整合算出softmax得到结果。

看一下时域

空域

loss function
采用了triplet loss 和softmax
Triplet是在目标检测常用的loss
我们在训练时，都是采用mini-batch成批成批进行训练的，在一批特征矩阵中。
有属于我自己这个人图像的map 有属于别人的map
那么我从自己这里找到一个和我最不像的map作为positive
选一个不是我的和我最像的map作为negative
让我们三者之间去学习差异，再反向传播就可以让模型知道我们要学什么。
softmax cross-entropy就不说了，分类用的，学习分布之间的关系差异。

那么这么做了之后效果怎么样

数据集采用MARS和Duke都是在校园摄像头下采集的。
行人重识别还有一个问题，就是别看我们在这个校园下识别的好，其实放到其他场景下效果直线下滑。所以行人重识别多场景的数据集还是一个值得做的点。上个月中山大学公布了一个行人重识别历史最大的数据集，这篇文章也是中山大学的。

再看看评估标准
用的是rank1 和rank5 这个都熟悉吧，找到的概率最大的作为结果正确的急速rank1
找5个有一个对了的就算对的是rank5.
mAP值 m是求平均的意思
AP就是我查一个图片给我返回来一组图片结果，正确的应该是在返回的第几个。
黑板一画。

然后对比其他模型我肯定最优。

对比三个分支，发现缺一不可

把图网络换成全连接层，发现不可，证明图网络有用。
肯定有用，因为我人眼来找一个人不可能只看一帧图像，肯定大脑里建立了多针图像和这个人身体部位的关联关系。

创新点读

结论肯定就是有效被

看了其他其他论文有怎么解决行人重识别这些问题的。
最大问题是怎么落地

同样是上个月旷世研究院提出这篇文章，很值得读。用到的方法都很恰到好处，很多论文提出一个方法很生硬，这篇文章没有那种感觉。是基于骨骼关键点来学习高阶语义。相似度计算也是用了图神经网络做图匹配的方法。
文章我就不讲了时间不够，不过也写了总结的文章可以参考我的博客。

我看了这篇文章其实并没有很多创新点，要说创新的地方就是设计他的STGCN网络结构。对上面的问题只能说一定程度缓解，提升个多少点精度而已，并没有完全解决什么问题。
